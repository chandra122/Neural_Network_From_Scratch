ðŸ§  Neural Network from Scratch
Built a complete Multi-Layer Perceptron (MLP) framework using only NumPy.
**Mathematical Implementation**: Forward/Backward propagation, Chain Rule, Xavier Initialization.
**Optimizers:** Implemented SGD with Momentum and Adam from scratch.
**Activations:** ReLU, Sigmoid, Tanh, Leaky ReLU.
**Results:** Achieved near-zero loss on MNIST Handwritten Digit classification.
